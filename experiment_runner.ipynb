{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98efc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_ds, val_ds = tfds.load('caltech101', split=['train[:80%]', 'train[80%:]'], as_supervised=True)\n",
    "train_ds = train_ds.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "num_classes = tfds.builder('caltech101').info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0618738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Builder\n",
    "def build_densenet_model(cfg):\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = cfg[\"train_entire_model\"]\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(cfg[\"dense_units\"], activation=cfg[\"activation\"])(x)\n",
    "    x = layers.Dropout(cfg[\"dropout_rate\"])(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    if cfg[\"optimiser\"] == 'adam':\n",
    "        opt = optimizers.Adam(learning_rate=cfg[\"learning_rate\"])\n",
    "    elif cfg[\"optimiser\"] == 'adagrad':\n",
    "        opt = optimizers.Adagrad(learning_rate=cfg[\"learning_rate\"])\n",
    "    elif cfg[\"optimiser\"] == 'rmsprop':\n",
    "        opt = optimizers.RMSprop(learning_rate=cfg[\"learning_rate\"], momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimiser: {cfg['optimiser']}\")\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Plot\n",
    "def plot_training(history, name):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.title(f\"{name} Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f\"{name} Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f\"plots/{name}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.0001_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.0001_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.0001_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.0001_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9520d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.0001_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.0001_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.0001_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.0001_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5159cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.0001_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.0001_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631a0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.0001_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.0001_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.0001_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.0001_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.0001_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.0001_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1980db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.001_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.001_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.001_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.001_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7872654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.001_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.001_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.001_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.001_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.001_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.001_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.001_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.001_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5895f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.001_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.001_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c38cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.001_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.001_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbcc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.01_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.01_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.01_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.01_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383bb8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.01_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.01_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c26bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.01_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.01_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633dd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.01_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.01_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.01_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.01_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb031ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.01_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.01_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda98fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adagrad_lr0.01_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adagrad_lr0.01_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.0001_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.0001_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.0001_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.0001_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e36926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.0001_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.0001_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.0001_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.0001_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.0001_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.0001_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.0001_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.0001_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.0001_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.0001_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a086ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.0001_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.0001_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.001_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.001_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89804bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.001_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.001_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.001_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.001_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.001_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.001_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c638ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.001_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.001_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d718b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.001_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.001_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a86d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.001_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.001_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.001_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.001_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.01_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.01_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f39fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.01_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.01_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6390184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.01_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.01_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.01_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.01_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c894c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.01_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.01_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec28431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.01_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.01_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.01_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.01_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe202b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: adam_lr0.01_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/adam_lr0.01_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.0001_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.0001_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.0001_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.0001_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.0001_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.0001_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb19310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.0001_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.0001_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.0001_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.0001_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.0001_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.0001_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.0001_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.0001_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2216568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.0001_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.0001_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.001_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.001_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675027e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.001_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.001_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ad174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.001_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.001_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8893ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.001_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.001_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.001_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.001_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53737605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.001_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.001_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.001_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.001_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.001_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.001_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.01_drop0.2_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.01_drop0.2_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ecc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.01_drop0.2_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.01_drop0.2_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.01_drop0.2_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.01_drop0.2_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6deb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.01_drop0.2_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.01_drop0.2_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.01_drop0.3_units128_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.01_drop0.3_units128_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.01_drop0.3_units128_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.01_drop0.3_units128_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba77e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.01_drop0.3_units512_elu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.01_drop0.3_units512_elu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: rmsprop_lr0.01_drop0.3_units512_relu\n",
    "\n",
    "# Load config\n",
    "with open(\"experiment_configs/rmsprop_lr0.01_drop0.3_units512_relu.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Skip if model already exists\n",
    "model_path = f\"models/{cfg['name']}.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Skipping {cfg['name']} — model already exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Build model and setup callbacks\n",
    "model = build_densenet_model(cfg)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=cfg[\"num_epochs\"],\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training(history, cfg['name'])\n",
    "\n",
    "# Save result\n",
    "final_result = {\n",
    "    \"experiment\": cfg[\"name\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "    \"epochs_ran\": len(history.history[\"val_loss\"]),\n",
    "}\n",
    "df = pd.DataFrame([final_result])\n",
    "csv_path = \"results/experiment_results.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df_existing = pd.read_csv(csv_path)\n",
    "    df_combined = pd.concat([df_existing, df])\n",
    "else:\n",
    "    df_combined = df\n",
    "df_combined.to_csv(csv_path, index=False)\n",
    "print(f\"Completed: {cfg['name']}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
